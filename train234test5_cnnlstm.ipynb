{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f42e0a-d391-4acd-933f-3bd54aa97586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mat_data_set = [()]\n",
    "# Load MATLAB file\n",
    "mat_file = r'C:\\Device5_ 1.mat' \n",
    "mat_data = scipy.io.loadmat(mat_file)\n",
    "mat_data_set = np.append(mat_data_set, mat_data)\n",
    "\n",
    "mat_file = r'C:\\Device2  1.mat' \n",
    "mat_data = scipy.io.loadmat(mat_file)\n",
    "mat_data_set = np.append(mat_data_set, mat_data)\n",
    "\n",
    "mat_file = r'C:\\Device3  1.mat' \n",
    "mat_data = scipy.io.loadmat(mat_file)\n",
    "mat_data_set = np.append(mat_data_set, mat_data)\n",
    "\n",
    "mat_file = r'C:\\Device4  1.mat' \n",
    "mat_data = scipy.io.loadmat(mat_file)\n",
    "mat_data_set = np.append(mat_data_set, mat_data)\n",
    "\n",
    "#j=0 dev5\n",
    "#j=1 dev2\n",
    "#j=2 dev3\n",
    "#j=3 dev4\n",
    "\n",
    "ce_window_smooth = [None] * len(mat_data_set)\n",
    "\n",
    "for j in range(len(mat_data_set)):\n",
    "    measurement = mat_data_set[j]['measurement']\n",
    "    transient = measurement['transient']\n",
    "    \n",
    "    total_time = 0\n",
    "    new_time = 0\n",
    "    original = 0 \n",
    "    time = np.array([])\n",
    "    ce_data_list = []\n",
    "    \n",
    "    for i in range(len(transient[0,0][0])):\n",
    "        date_str = transient[0,0][0][i][0][0]\n",
    "        time_str = date_str.split(' ')[1]\n",
    "        hour, minute, second = map(int, time_str.split(':'))\n",
    "        \n",
    "        new_time = hour*3600 + minute*60 + second\n",
    "        if i == 0:\n",
    "            original = new_time\n",
    "        total_time = new_time - original\n",
    "    \n",
    "        time = np.append(time, total_time)\n",
    "        \n",
    "        ce_data = transient[0,0][0][i][2][0][0][3][0]\n",
    "        ce_data_list.append(ce_data)\n",
    "    \n",
    "    ce_data_array = np.array(ce_data_list) \n",
    "    \n",
    "    ce_sampling_data = [()]\n",
    "    for i in range(len(ce_data_array)):\n",
    "        if time[i]>=2000 and np.min(ce_data_array[i])<=4.0:\n",
    "            break\n",
    "        ce_sampling_data = np.append(ce_sampling_data, np.average(ce_data_array[i]))\n",
    "    \n",
    "    def calculate_weighted_average(x, t, span=15):\n",
    "        theta = 2 / (span + 1)\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "    \n",
    "        for i in range(t + 1):\n",
    "            weight = (1 - theta) ** (t - i)\n",
    "            numerator += weight * x[i]\n",
    "            denominator += weight\n",
    "    \n",
    "        yt = numerator / denominator\n",
    "        return yt\n",
    "    \n",
    "    span = 15\n",
    "    ce_window_smooth[j] = np.zeros(len(ce_sampling_data))\n",
    "    for t in range(len(ce_sampling_data)):\n",
    "        ce_window_smooth[j][t] = calculate_weighted_average(ce_sampling_data, t, span)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "946fc22c-61c4-4ddc-8422-f67348b1ddd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "106\n",
      "96\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "for q in range(len(mat_data_set)):\n",
    "    len_ori = len(ce_window_smooth[q])\n",
    "    print(len_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87fe9a61-7ee5-4725-9a8b-f8e646038b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_window_smooth_new = [None]*len(mat_data_set)\n",
    "len_larger = len(ce_window_smooth[3])\n",
    "for q in range(len(mat_data_set)):\n",
    "    ce_window_smooth_new[q] = ce_window_smooth[q][0:len_larger]\n",
    "    #print(len(output_array_new[q])-len(ce_window_smooth[q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41156ae1-40b7-4a78-9ad7-b36316d68e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "91\n",
      "91\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "for q in range(len(mat_data_set)):\n",
    "    len_ori = len(ce_window_smooth_new[q])\n",
    "    print(len_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fab75ea-4637-4abb-89e3-0183736813b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 73\u001b[0m\n\u001b[0;32m     71\u001b[0m data_test \u001b[38;5;241m=\u001b[39m ce_window_smooth[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data_test)):\n\u001b[1;32m---> 73\u001b[0m     test_input \u001b[38;5;241m=\u001b[39m data_test[i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Input for testing (one element at a time)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(test_input\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     75\u001b[0m     test_output\u001b[38;5;241m.\u001b[39mappend(output\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define the CNN + LSTM model without MaxPool1d\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        # Define CNN layer (adjust kernel_size and padding)\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)  # Convolutional Layer\n",
    "        self.relu = nn.ReLU()  # ReLU activation\n",
    "        # Define LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=16, hidden_size=32, num_layers=1, batch_first=True)\n",
    "        # Fully connected layer after LSTM\n",
    "        self.fc1 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(f\"Input shape: {x.shape}\")\n",
    "        x = x.unsqueeze(1)  # Add channel dimension (1 channel in this case for CNN)\n",
    "        x = self.conv1(x)  # Convolution operation\n",
    "       # print(f\"After Conv1D shape: {x.shape}\")\n",
    "        x = self.relu(x)  # Apply ReLU activation\n",
    "        # x = self.pool(x)  # Removed MaxPooling\n",
    "        x = x.permute(0, 2, 1)  # Rearrange for LSTM (batch, seq_len, input_size)\n",
    "        #print(f\"After permute shape: {x.shape}\")\n",
    "        x, _ = self.lstm(x)  # Apply LSTM\n",
    "        #print(f\"After LSTM shape: {x.shape}\")\n",
    "        x = x[:, -1, :]  # Use the output of the last LSTM timestep\n",
    "        x = self.fc1(x)  # Fully connected layer to get final output\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = CNN_LSTM()\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Training loop (element-wise training)\n",
    "num_epochs = 100\n",
    "\n",
    "for q in range(len(mat_data_set)):\n",
    "    model.train()\n",
    "    if q in [1, 2, 3]:\n",
    "        data = ce_window_smooth[q]\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(len(data)):            \n",
    "                inputs = torch.tensor(data[i], dtype=torch.float32)  # Convert numpy array to tensor\n",
    "                labels = torch.tensor(data[i], dtype=torch.float32)  # Convert numpy array to tensor\n",
    "                \n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                # Forward pass\n",
    "                output = model(input_data)\n",
    "        \n",
    "                # Calculate loss\n",
    "                loss = criterion(output, target.unsqueeze(0))\n",
    "        \n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "\n",
    "# Test the model on the test data (element-wise)\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_output = []\n",
    "    data_test = ce_window_smooth[0]\n",
    "    for i in range(len(data_test)):\n",
    "        test_input = data_test[i].unsqueeze(0)  # Input for testing (one element at a time)\n",
    "        output = model(test_input.unsqueeze(0))\n",
    "        test_output.append(output.item())\n",
    "    print(f'Test output: {test_output}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d06b0-2ca8-49c8-883b-532bad2eebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.plot(test_output, label='Predicted')\n",
    "plt.plot(ce_window_smooth_new[0], label='Actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec6b81f-c1b0-4588-af28-57f84dac3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate MSE\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Function to calculate R² (Coefficient of Determination)\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)  # Residual sum of squares\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)  # Total sum of squares\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "# Function to calculate MAE\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b59776-e957-42b1-8d7e-775f213bdbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = ce_window_smooth_new[0]\n",
    "\n",
    "y_pred = cnnlstm_out\n",
    "# Calculate MSE\n",
    "mse_cnnlstm = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "# Calculate R²\n",
    "r2_cnnlstm = r2_score(y_true, y_pred)*100\n",
    "\n",
    "# Calculate MAE\n",
    "mae_cnnlstm = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(mse_cnnlstm)\n",
    "print(r2_cnnlstm)\n",
    "print(mae_cnnlstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6d703-46d4-483e-9bc5-924cf2baee66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6efbe-73a0-4415-ad22-b3f9ab823026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
